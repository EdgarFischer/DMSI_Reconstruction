{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21e838af",
   "metadata": {},
   "source": [
    "# ***Set Parameters to define model etc***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9a95c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Undersampling Strategy:#####\n",
    "Undersampling = \"Regular\" # Options: Regular or Possoin\n",
    "Sampling_Mask = \"Complementary_Masks\" #Options: Single_Combination or One_Mask Complementary_Masks\n",
    "AF = 2 #  acceleration factor\n",
    "\n",
    "#### Model Input and Output ####\n",
    "GT_Data = \"LowRank\" # Options: FullRank LowRank for GROUNDTRUTH!\n",
    "Low_Rank_Input = True ## apply low rank to the input as well if True\n",
    "trancuate_t = 96 # set this parameter to control at which time step you stop using the signal\n",
    "\n",
    "####M Model Parameters ####\n",
    "batch_size=32   # Test for github\n",
    "num_convs = 6\n",
    "\n",
    "Test_Set = 0 # always trained with 0 test set !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f829fe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('../scripts')\n",
    "sys.path.append('../models')\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= '1' #, this way I would choose GPU 3 to do the work\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import zoom # for compressing images / only for testing purposes to speed up NN training\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from data_preparation import *\n",
    "from data_undersampling import *\n",
    "from output_statistics import *\n",
    "\n",
    "from interlacer_layer_modified import *\n",
    "from Residual_Interlacer_modified import *\n",
    "from skimage.metrics import structural_similarity as ssim \n",
    "\n",
    "#### Model import correct model\n",
    "from Unet import * #from Naive_CNN_3D_Residual_No_Batch_Norm import *\n",
    "\n",
    "grouped_time_steps = 8 # Set how many subsequent time steps you want to give to the network at once. Values allowed: 1, 2, 4, 8 (because it has to divide 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96c9314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Define ground truth path####\n",
    "if GT_Data == \"FullRank\":\n",
    "    ground_truth_path = \"../data/Ground_Truth/Full_Rank/P03-P08_truncated_k_space.npy\"\n",
    "elif GT_Data == \"LowRank\":\n",
    "    ground_truth_path = \"../data/Ground_Truth/Low_Rank/LR_8_P03-P08_self.npy\"\n",
    "\n",
    "#### Define Input Data path\n",
    "undersampled_data_path = \"../data/Undersampled_Data/\"+Undersampling+f'/AF_{AF}/'+Sampling_Mask+'/data.npy'\n",
    "\n",
    "#### Definie Model path\n",
    "if GT_Data == \"FullRank\":\n",
    "    saved_model_path = f\"../saved_models/UNet_3D/xyz_T/Full2Full/\"+Undersampling+f'/AF_{AF}/'+f'Truncate_t_{trancuate_t}/'+Sampling_Mask+f'/best_model.pth'\n",
    "elif GT_Data == \"LowRank\":\n",
    "    saved_model_path = f\"../saved_models/UNet_3D/xyz_T/Low2Low/\"+Undersampling+f'/AF_{AF}/'+f'Truncate_t_{trancuate_t}/'+Sampling_Mask+f'/best_model.pth'\n",
    "    \n",
    "    \n",
    "#### load data!\n",
    "Ground_Truth = np.load(ground_truth_path)\n",
    "Undersampled_Data = np.load(undersampled_data_path)\n",
    "MASKS = np.load(\"../data/masks.npy\")\n",
    "\n",
    "####\n",
    "mask_expanded = MASKS[:, :, :, None, None, :]  # Now shape is (22,22,21,1,1,6)\n",
    "# Use broadcasting to \"repeat\" the mask along these new axes:\n",
    "mask_extended = np.broadcast_to(mask_expanded, (22, 22, 21, 96, 8, 6))\n",
    "mask_extended = mask_extended + 1J*mask_extended\n",
    "\n",
    "#### additionally make LowRank 8 transformation on input of network, this improves the error significantly!\n",
    "if Low_Rank_Input:\n",
    "    Undersampled_Data[...,0] = low_rank(Undersampled_Data[...,0], 8)\n",
    "    Undersampled_Data[...,1] = low_rank(Undersampled_Data[...,1], 8)\n",
    "    Undersampled_Data[...,2] = low_rank(Undersampled_Data[...,2], 8)\n",
    "    Undersampled_Data[...,3] = low_rank(Undersampled_Data[...,3], 8)\n",
    "    Undersampled_Data[...,4] = low_rank(Undersampled_Data[...,4], 8)\n",
    "    Undersampled_Data[...,5] = low_rank(Undersampled_Data[...,5], 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1029ce8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train_Test_Split ####\n",
    "ground_truth_train, ground_truth_test = Ground_Truth[:,:,:,:trancuate_t,:,1:6], Ground_Truth[:,:,:,:trancuate_t,:,Test_Set]  \n",
    "Train_Mask, Test_Mask = mask_extended[:,:,:,:trancuate_t,:,1:6], mask_extended[:,:,:,:trancuate_t,:,Test_Set]\n",
    "\n",
    "#### Assign undersampled network input ####\n",
    "NN_input_train, NN_input_test = Undersampled_Data[:,:,:,:trancuate_t,:,1:6], Undersampled_Data[:,:,:,:trancuate_t,:,Test_Set]\n",
    "\n",
    "####swap t and T to prepare for Network\n",
    "ground_truth_train, ground_truth_test = np.swapaxes(ground_truth_train, 3,4), np.swapaxes(ground_truth_test, 3,4)\n",
    "NN_input_train, NN_input_test = np.swapaxes(NN_input_train, 3,4), np.swapaxes(NN_input_test, 3,4)\n",
    "\n",
    "\n",
    "#### Collapse ununsed dimensions ####\n",
    "ground_truth_train, ground_truth_test = ground_truth_train.reshape(22, 22, 21,8, -1), ground_truth_test.reshape(22, 22, 21,8, -1)\n",
    "NN_input_train, NN_input_test = NN_input_train.reshape(22, 22, 21,8, -1), NN_input_test.reshape(22, 22, 21,8, -1)\n",
    "Mask_train, Mask_test = Train_Mask.reshape(22, 22, 21,8, -1), Test_Mask.reshape(22, 22, 21,8, -1)\n",
    "\n",
    "#### Normalize data #####\n",
    "normalized_input_train, normalized_ground_truth_train, norm_values_train = normalize_data_per_image_new(NN_input_train, ground_truth_train)\n",
    "normalized_input_test, normalized_ground_truth_test, norm_values_test = normalize_data_per_image_new(NN_input_test, ground_truth_test)\n",
    "\n",
    "#### reshape for pytorch ####\n",
    "train_data, train_labels  = reshape_for_pytorch(normalized_input_train, grouped_time_steps), reshape_for_pytorch(normalized_ground_truth_train, grouped_time_steps)\n",
    "test_data, test_labels = reshape_for_pytorch(normalized_input_test, grouped_time_steps), reshape_for_pytorch(normalized_ground_truth_test, grouped_time_steps)\n",
    "train_mask, test_mask = reshape_for_pytorch(Mask_train, grouped_time_steps), reshape_for_pytorch(Mask_test, grouped_time_steps)\n",
    "\n",
    "#### increase dimensions to 24x24x24 for Unet\n",
    "pad_width = ((0, 0), (0, 0), (1, 1), (1, 1), (1, 2))\n",
    "train_data, train_labels = np.pad(train_data, pad_width, mode='constant', constant_values=0), np.pad(train_labels, pad_width, mode='constant', constant_values=0)\n",
    "test_data, test_labels = np.pad(test_data, pad_width, mode='constant', constant_values=0), np.pad(test_labels, pad_width, mode='constant', constant_values=0)\n",
    "train_mask, test_mask = np.pad(train_mask, pad_width, mode='constant', constant_values=0), np.pad(test_mask, pad_width, mode='constant', constant_values=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68c1c105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Set parameters ####\n",
    "\n",
    "augment = RandomAugment3D(rotation_range=0.3, shift_pixels=1,\n",
    "                          apply_phase=False, apply_rotation=False, apply_shift=False)\n",
    "\n",
    "# Create TensorDataset instances\n",
    "train_dataset = TensorDatasetWithAugmentation(train_data, train_labels, train_mask, norm_values_train, transform=augment)\n",
    "test_dataset = TensorDatasetWithAugmentation(test_data, test_labels, test_mask, norm_values_test, transform=None)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "  # Number of convolutional layers\n",
    "model = UNet3D(grouped_time_steps=grouped_time_steps, use_batch_norm=False).to(device)\n",
    "\n",
    "#saved_model_path = \"../saved_models/Naive_CNN_3D_AF_3_Non_Residual/5Layer/model.pth\"  # Replace with your file path\n",
    "\n",
    "# 2. Load the model's state_dict (weights) from the saved file\n",
    "\n",
    "checkpoint = torch.load(saved_model_path, map_location=device)\n",
    "# Extract the model state_dict\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a49ce16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "\n",
    "    # Initialize lists to store outputs and labels\n",
    "outputs_list = []\n",
    "inputs_img_list = []\n",
    "input_kspace_list = []\n",
    "labels_list = []\n",
    "\n",
    "    # Disable gradient computation for efficiency\n",
    "with torch.no_grad():\n",
    "    for data, labels, masks, _ in test_loader:\n",
    "            # Unpack the tuple returned by the dataset\n",
    "        inputs_img = data\n",
    "\n",
    "            # Move the tensors to the appropriate device\n",
    "        inputs_img = inputs_img.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "            # Pass the inputs as a tuple to the model\n",
    "        outputs = model((inputs_img))\n",
    "\n",
    "            # If outputs is a tuple, extract the first element\n",
    "        if isinstance(outputs, tuple):\n",
    "            outputs = outputs[0]\n",
    "\n",
    "            # Append outputs and labels to the lists\n",
    "        outputs_list.append(outputs.cpu().numpy())  # Convert to numpy and move to CPU\n",
    "        labels_list.append(labels.cpu().numpy())   # Convert to numpy and move to CPU\n",
    "        inputs_img_list.append(inputs_img.cpu().numpy())\n",
    "\n",
    "\n",
    "#     # Convert to final arrays\n",
    "outputs_array = np.concatenate(outputs_list, axis=0)\n",
    "inputs_img = np.concatenate(inputs_img_list, axis=0)\n",
    "labels_array = np.concatenate(labels_list, axis=0)\n",
    "\n",
    "outputs_array = outputs_array[:, :, 1:-1, 1:-1, 1:-2]  # (N, C, 22, 22, 21)\n",
    "inputs_img = inputs_img[:, :, 1:-1, 1:-1, 1:-2]\n",
    "labels_array = labels_array[:, :, 1:-1, 1:-1, 1:-2]   \n",
    "\n",
    "outputs_array = inverse_reshape_for_pytorch(outputs_array, grouped_time_steps)\n",
    "inputs_img = inverse_reshape_for_pytorch(inputs_img, grouped_time_steps)\n",
    "labels_array = inverse_reshape_for_pytorch(labels_array, grouped_time_steps)\n",
    "\n",
    "# outputs_array = outputs_array[:,0,:,:,:]+1J*outputs_array[:,1,:,:,:]\n",
    "# inputs_img = inputs_img[:,0,:,:,:]+1J*inputs_img[:,1,:,:,:]\n",
    "# labels_array = labels_array[:,0,:,:,:]+1J*labels_array[:,1,:,:,:]\n",
    "    \n",
    "# outputs_array = outputs_array.transpose(1, 2, 3, 0)\n",
    "# inputs_img = inputs_img.transpose(1, 2, 3, 0)\n",
    "# labels_array = labels_array.transpose(1, 2, 3, 0)\n",
    "\n",
    "denormalized_input = denormalize_data_per_image(inputs_img, norm_values_test.reshape(-1))\n",
    "denormalized_output = denormalize_data_per_image(outputs_array, norm_values_test.reshape(-1))\n",
    "denormalized_labels = denormalize_data_per_image(labels_array, norm_values_test.reshape(-1))\n",
    "\n",
    "Model_Outputs_Test_Set = np.swapaxes(denormalized_output, -1, -2)\n",
    "# GT = denormalized_labels.reshape(22,22,21, trancuate_t, 8)\n",
    "\n",
    "# denormalized_input = reshape_for_pytorch(inputs_img, grouped_time_steps)\n",
    "# denormalized_output = reshape_for_pytorch(denormalized_output, grouped_time_steps)\n",
    "# denormalized_labels = reshape_for_pytorch(denormalized_labels, grouped_time_steps)\n",
    "\n",
    "# denormalized_output = inverse_preprocess(denormalized_output, trancuate_t, T, grouped_time_steps)\n",
    "# denormalized_labels = inverse_preprocess(denormalized_labels, trancuate_t, T, grouped_time_steps)\n",
    "\n",
    "#     return denormalized_output, denormalized_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405101dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model_Outputs_Test_Set, ground_truth = Process_Model_Output(test_loader, model, device, trancuate_t, 8, grouped_time_steps, norm_values_test)\n",
    "Undersampled_Data = np.load(undersampled_data_path)\n",
    "\n",
    "Undersampled_Data[...,0] = low_rank(Undersampled_Data[...,0], 8)\n",
    "\n",
    "Ground_Truth = np.load(ground_truth_path)\n",
    "ground_truth = Ground_Truth[:,:,:,:trancuate_t,:,0]\n",
    "\n",
    "mask = np.load('../data/masks.npy')\n",
    "mask_5 = mask[:,:,:,0]\n",
    "mask_5D = mask_5[:,:,:, np.newaxis, np.newaxis]\n",
    "\n",
    "Model_Outputs_Test_Set = Model_Outputs_Test_Set*mask_5D\n",
    "ground_truth = ground_truth*mask_5D\n",
    "norm_values_test = np.ones((trancuate_t,8))\n",
    "### to be fair, I compute a LR approximation, as a trivial baseline comparison + apply the mask\n",
    "model_input = Undersampled_Data[...,0]*mask_5D\n",
    "model_input = model_input[:,:,:,:trancuate_t,:]\n",
    "\n",
    "plot_general_statistics(Model_Outputs_Test_Set, model_input, ground_truth, trancuate_t, norm_values_test, label = \"Model Output\", label2 = \"Model Input\")\n",
    "plot_general_statistics_PSNR(Model_Outputs_Test_Set, model_input, ground_truth, trancuate_t, norm_values_test, label = \"Model Output\", label2 = \"Model Input\")\n",
    "plot_general_statistics_SSIM(Model_Outputs_Test_Set, model_input, ground_truth, trancuate_t, norm_values_test, label = \"Model Output\", label2 = \"Model Input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ff1d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = 50 #50 = Water, 60 Glucose, 24 Glx\n",
    "T = 7\n",
    "comparison_Plot_3D_vs_Ifft(Model_Outputs_Test_Set, ground_truth, model_input, tf, T, domain=\"spectral\", label = \"Model Output\", label2 = \"Model Input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e94d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = 5 #50 = Water, 60 Glucose, 24 Glx\n",
    "T = 7\n",
    "\n",
    "### NOTE: The labels are off, due to swapping I actually show z-y images along the x axis\n",
    "ground_truth_swapped = np.swapaxes(ground_truth, 0, 2)\n",
    "Model_Outputs_Test_Set_swapped = np.swapaxes(Model_Outputs_Test_Set, 0, 2)\n",
    "model_input_swapped = np.swapaxes(model_input, 0, 2)\n",
    "\n",
    "comparison_Plot_3D_vs_Ifft(Model_Outputs_Test_Set_swapped, ground_truth_swapped, model_input_swapped, tf, T, domain=\"time\", label = \"Model Output\", label2 = \"Model Input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d4907f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_spectral = np.fft.fftshift(np.fft.fft(ground_truth, axis=-2), axes=-2)\n",
    "model_pred_spectral = np.fft.fftshift(np.fft.fft(Model_Outputs_Test_Set, axis=-2), axes=-2)\n",
    "IFF_LR_8 = np.fft.fftshift(np.fft.fft(model_input, axis=-2), axes=-2)\n",
    "\n",
    "IFF_LR_8 = np.fft.fftshift(np.fft.fft(model_input, axis=-2), axes=-2)\n",
    "# Fixed indices for x, y, and T:\n",
    "# ----------------------------------------------------------------------\n",
    "# Fixed indices for x, y, and T\n",
    "# ----------------------------------------------------------------------\n",
    "x_fixed = 15\n",
    "y_fixed = 15\n",
    "T_fixed = 7\n",
    "\n",
    "num_z = 21  # Number of z slices\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Create a figure with 2 columns:\n",
    "#   Column 1 -> Absolute value plots\n",
    "#   Column 2 -> Residuals (GT - [Others])\n",
    "# ----------------------------------------------------------------------\n",
    "fig, axes = plt.subplots(nrows=num_z, ncols=2, figsize=(16, num_z * 3.5), sharex=True)\n",
    "\n",
    "# If there's only one row, ensure axes is 2D\n",
    "if num_z == 1:\n",
    "    axes = np.array([axes])\n",
    "\n",
    "for z in range(num_z):\n",
    "    # Extract the spectra at [x_fixed, y_fixed, z, :, T_fixed]\n",
    "    gt_spec  = ground_truth_spectral[x_fixed, y_fixed, z, :, T_fixed]\n",
    "    mp_spec  = model_pred_spectral[x_fixed, y_fixed, z, :, T_fixed]\n",
    "    iff_spec = IFF_LR_8[x_fixed, y_fixed, z, :, T_fixed]\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # Column 1: Plot absolute spectra\n",
    "    # ------------------------------------------------------------------\n",
    "    ax_abs = axes[z, 0]\n",
    "    ax_abs.plot(np.abs(gt_spec),  label='Ground Truth',    color='blue')\n",
    "    ax_abs.plot(np.abs(mp_spec),  label='Model Prediction',color='orange')\n",
    "    ax_abs.plot(np.abs(iff_spec), label='IFFT + LR 8',     color='green')\n",
    "    ax_abs.set_ylim(-50000, 350000)\n",
    "    # Row label on the Y-axis\n",
    "    ax_abs.set_ylabel(f'z = {z}')\n",
    "    \n",
    "    if z == 0:\n",
    "        ax_abs.set_title('Absolute Value')\n",
    "    ax_abs.legend(loc='upper left')\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # Column 2: Plot residuals (Ground Truth - [Others])\n",
    "    # ------------------------------------------------------------------\n",
    "    ax_res = axes[z, 1]\n",
    "    \n",
    "    residual_gt_mp  = np.abs(gt_spec) - np.abs(mp_spec)\n",
    "    residual_gt_iff = np.abs(gt_spec) - np.abs(iff_spec)\n",
    "    \n",
    "    ax_res.plot(residual_gt_mp,  label='GroundTruth - Model',        color='orange')\n",
    "    ax_res.plot(residual_gt_iff, label='GroundTruth - IFFT + LR 8',  color='green')\n",
    "\n",
    "    if z == 0:\n",
    "        ax_res.set_title('Residual')\n",
    "    ax_res.legend(loc='upper left')\n",
    "    ax_res.set_ylim(-50000, 350000)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561d3d65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
