{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "In the Data folder file I showed that t>20 basically corresponds to noise. Here I want to check if the network performance improves if I throw out this noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('../scripts')\n",
    "sys.path.append('../models')\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= '0' #, this way I would choose GPU 3 to do the work\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import zoom # for compressing images / only for testing purposes to speed up NN training\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from data_preparation import *\n",
    "from data_undersampling import *\n",
    "from output_statistics import *\n",
    "\n",
    "from interlacer_layer_modified import *\n",
    "from Residual_Interlacer_modified import *\n",
    "from skimage.metrics import structural_similarity as ssim \n",
    "\n",
    "trancuate_t = 96 # set this parameter to control at which time step you stop using the signal\n",
    "# Set how many subsequent time steps you want to give to the network at once. Values allowed: 1, 2, 4, 8 (because it has to divide 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "num_convs = 10\n",
    "grouped_time_steps = 8 \n",
    "Batch_Norm = False\n",
    "\n",
    "\n",
    "#### Model import correct model\n",
    "from Naive_CNN_3D import * #from Naive_CNN_3D_Residual_No_Batch_Norm import *\n",
    "\n",
    "AF = 3 #                # defined so far for noisy:3, 5, 10, 20, 40\n",
    "\n",
    "#saved_model_path = \"../saved_models/Naive_CNN_3D_AF_3_Non_Residual/Layer/model.pth\"  # Replace with your file path\n",
    "#saved_model_path = \"../saved_models/Naive_CNN_3D_AF_3_possoin_r0/5Layer/model.pth\"\n",
    "#saved_model_path = \"../saved_models/Naive_CNN_3D_AF_3_Alternating/5Layer/model.pth\"\n",
    "#saved_model_path = \"../saved_models/Naive_CNN_3D_Non_Residual_AF_5_possoin_r0/5Layer/model.pth\"\n",
    "saved_model_path = f\"../saved_models/Fitted_Naive_CNN_3D_AF_{AF}_possoin_r0_T8/{num_convs}Layer/model.pth\"\n",
    "\n",
    "#### Load data ####\n",
    "Ground_Truth = np.load('../data/P04_And_P08_Spectral_Fit.npy')\n",
    "\n",
    "Undersampled_Data = np.load(f'../data/Undersampled_Data/P04_P08_Fitted_undersampled_possoin_3D_fixed_r0_AF_{AF}.npy')\n",
    "\n",
    "#Undersampled_Data = np.load('../data/Undersampled_Data/combined_undersampled_possoin_3D_fixed_r0_AF_5.npy')\n",
    "#Undersampled_Data = np.load('../data/Undersampled_Data/combined_undersampled_Alternating_AF_3.npy')\n",
    "#Undersampled_Data = np.load('../data/Undersampled_Data/combined_undersampled_possoin_3D_fixed_r0_AF_3.npy') ## Data set with accerleration factor 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train_Test_Split ####\n",
    "ground_truth_train, ground_truth_test = Ground_Truth[:,:,:,:,:,0], Ground_Truth[:,:,:,:,:,1]  # Method: Leave last MRSI measurement as test set\n",
    "\n",
    "#ground_truth_train = np.transpose(ground_truth_train, axes=(0, 1, 2, 4, 3))\n",
    "\n",
    "shape_train, shape_test = ground_truth_train.shape, ground_truth_test.shape\n",
    "\n",
    "# #### Assign undersampled network input ####\n",
    "NN_input_train, NN_input_test = Undersampled_Data[:,:,:,:,:,0], Undersampled_Data[:,:,:,:,:,1]\n",
    "\n",
    "# Transpose array such that T is next to z\n",
    "ground_truth_train = np.transpose(ground_truth_train, axes=(0, 1, 2, 4, 3))\n",
    "ground_truth_test = np.transpose(ground_truth_test, axes=(0, 1, 2, 4, 3))\n",
    "NN_input_train = np.transpose(NN_input_train, axes=(0, 1, 2, 4, 3))\n",
    "NN_input_test = np.transpose(NN_input_test, axes=(0, 1, 2, 4, 3))\n",
    "\n",
    "# #### Collapse ununsed dimensions ####\n",
    "ground_truth_train, ground_truth_test = ground_truth_train.reshape(22, 22, 21, 8, -1), ground_truth_test.reshape(22, 22, 21, 8, -1)\n",
    "NN_input_train, NN_input_test = NN_input_train.reshape(22, 22, 21, 8, -1), NN_input_test.reshape(22, 22, 21, 8, -1)\n",
    "\n",
    "# #### Normalize data #####\n",
    "normalized_input_train, normalized_ground_truth_train, norm_values_train = normalize_data_per_image_new(NN_input_train, ground_truth_train)\n",
    "normalized_input_test, normalized_ground_truth_test, norm_values_test = normalize_data_per_image_new(NN_input_test, ground_truth_test)\n",
    "\n",
    "# #### reshape for pytorch ####\n",
    "train_data, train_labels  = reshape_for_pytorch(normalized_input_train, grouped_time_steps), reshape_for_pytorch(normalized_ground_truth_train, grouped_time_steps)\n",
    "test_data, test_labels = reshape_for_pytorch(normalized_input_test, grouped_time_steps), reshape_for_pytorch(normalized_ground_truth_test, grouped_time_steps)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Set parameters ####\n",
    "\n",
    "# Create TensorDataset instances\n",
    "train_dataset = TensorDataset(train_data, train_labels)\n",
    "test_dataset = TensorDataset(test_data, test_labels)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "  # Number of convolutional layers\n",
    "model = Naive_CNN_3D(grouped_time_steps=grouped_time_steps, num_convs=num_convs,  use_batch_norm=False ).to(device)\n",
    "\n",
    "#saved_model_path = \"../saved_models/Naive_CNN_3D_AF_3_Non_Residual/5Layer/model.pth\"  # Replace with your file path\n",
    "\n",
    "# 2. Load the model's state_dict (weights) from the saved file\n",
    "\n",
    "checkpoint = torch.load(saved_model_path, map_location=device)\n",
    "# Extract the model state_dict\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Process_Model_Output(test_loader, model, device, trancuate_t, T, grouped_time_steps, abs_test_set = []): ## this is for a network that processes k-space and image space simulattenously (deeper)\n",
    "    \"\"\"\n",
    "    Compute model predictions and bring them back to the original unpreprocessed format for statistics.\n",
    "    Also output the ground truth in the same format.\n",
    "\n",
    "    Parameters:\n",
    "        test_loader (DataLoader): DataLoader for the test set.\n",
    "        model (torch.nn.Module): The trained PyTorch model.\n",
    "        device (torch.device): Device to perform computations on (e.g., 'cuda' or 'cpu').\n",
    "        inverse_preprocess (function): Function to revert preprocessing on the data.\n",
    "        t, T, grouped_time_steps: Parameters for inverse_preprocess function.\n",
    "        abs_test_set: needed to denormalize the original normalization of data, for comparison to other models NORMALIZATION VALUES\n",
    "\n",
    "    Returns:\n",
    "        tuple: The original shape of outputs and labels after inverse preprocessing.\n",
    "    \"\"\"\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize lists to store outputs and labels\n",
    "    outputs_list = []\n",
    "    inputs_img_list = []\n",
    "    input_kspace_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    # Disable gradient computation for efficiency\n",
    "    with torch.no_grad():\n",
    "        for data, labels in test_loader:\n",
    "            # Unpack the tuple returned by the dataset\n",
    "            inputs_img = data\n",
    "\n",
    "            # Move the tensors to the appropriate device\n",
    "            inputs_img = inputs_img.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Pass the inputs as a tuple to the model\n",
    "            outputs = model((inputs_img))\n",
    "\n",
    "            # If outputs is a tuple, extract the first element\n",
    "            if isinstance(outputs, tuple):\n",
    "                outputs = outputs[0]\n",
    "\n",
    "            # Append outputs and labels to the lists\n",
    "            outputs_list.append(outputs.cpu().numpy())  # Convert to numpy and move to CPU\n",
    "            labels_list.append(labels.cpu().numpy())   # Convert to numpy and move to CPU\n",
    "            inputs_img_list.append(inputs_img.cpu().numpy())\n",
    "\n",
    "\n",
    "#     # Convert to final arrays\n",
    "    outputs_array = np.concatenate(outputs_list, axis=0)\n",
    "    inputs_img = np.concatenate(inputs_img_list, axis=0)\n",
    "    labels_array = np.concatenate(labels_list, axis=0)\n",
    "\n",
    "    outputs_array = inverse_reshape_for_pytorch(outputs_array, grouped_time_steps)\n",
    "    inputs_img = inverse_reshape_for_pytorch(inputs_img, grouped_time_steps)\n",
    "    labels_array = inverse_reshape_for_pytorch(labels_array, grouped_time_steps)\n",
    "    \n",
    "    \n",
    "    denormalized_input = denormalize_data_per_image(inputs_img, abs_test_set)\n",
    "    denormalized_output = denormalize_data_per_image(outputs_array, abs_test_set)\n",
    "    denormalized_labels = denormalize_data_per_image(labels_array, abs_test_set)\n",
    "\n",
    "    denormalized_input = reshape_for_pytorch(inputs_img, grouped_time_steps)\n",
    "    denormalized_output = reshape_for_pytorch(denormalized_output, grouped_time_steps)\n",
    "    denormalized_labels = reshape_for_pytorch(denormalized_labels, grouped_time_steps)\n",
    "\n",
    "    denormalized_output = inverse_preprocess(denormalized_output, trancuate_t, 8, grouped_time_steps)\n",
    "    denormalized_labels = inverse_preprocess(denormalized_labels, trancuate_t, 8, grouped_time_steps)\n",
    "\n",
    "    return denormalized_output, denormalized_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_Outputs_Test_Set, ground_truth = Process_Model_Output(test_loader, model, device, trancuate_t, 8, grouped_time_steps, norm_values_test)\n",
    "\n",
    "Noise = ground_truth[:, :, :, 95, :]   # e.g. shape: (X, Y, Z, coil_dim)\n",
    "\n",
    "# Compute 2-norm per coil\n",
    "two_norm_per_big_T = np.sqrt(np.sum(np.abs(Noise)**2, axis=(0, 1, 2)))\n",
    "# shape of two_norm_per_coil is now (coil_dim,)\n",
    "\n",
    "# Take the mean across coils\n",
    "two_norm_noise_average = np.mean(two_norm_per_big_T)\n",
    "\n",
    "\n",
    "model_input = Undersampled_Data[:,:,:,:,:,1]\n",
    "\n",
    "Undersampling_Error = ground_truth[:, :, :, 0, :] - model_input[:, :, :, 0, :]  # e.g. shape: (X, Y, Z, coil_dim)\n",
    "\n",
    "# Compute 2-norm per coil\n",
    "two_norm_per_big_T = np.sqrt(np.sum(np.abs(Undersampling_Error)**2, axis=(0, 1, 2)))\n",
    "# shape of two_norm_per_coil is now (coil_dim,)\n",
    "\n",
    "# Take the mean across coils\n",
    "two_norm_US_average = np.mean(two_norm_per_big_T)\n",
    "\n",
    "Quotient = two_norm_US_average / two_norm_noise_average\n",
    "\n",
    "print(\"Undersampling error / noise error:\", Quotient)\n",
    "\n",
    "norm_values_test = norm_values_test.reshape(96,8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plot_general_statistics(Model_Outputs_Test_Set, model_input, ground_truth, trancuate_t, norm_values_test)\n",
    "plot_general_statistics_PSNR(Model_Outputs_Test_Set, model_input, ground_truth, trancuate_t, norm_values_test)\n",
    "plot_general_statistics_SSIM(Model_Outputs_Test_Set, model_input, ground_truth, trancuate_t, norm_values_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 1\n",
    "T = 7\n",
    "domain = \"spectral\"\n",
    "\n",
    "model_input = Undersampled_Data[:,:,:,:,:,1]\n",
    "\n",
    "comparison_Plot_3D_vs_Ifft(Model_Outputs_Test_Set, ground_truth, model_input, t, T, domain=domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Note that the Ratio is computed in the statistics cell\n",
    "\n",
    "AF = [3,5,10,20,40]\n",
    "Ratio = [0.73, 0.9, 1.04, 1.154, 1.73]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(AF, Ratio, marker='o', linestyle='-', label='Undersampling Error to Noise Error Ratio vs AF')\n",
    "\n",
    "plt.axhline(y=0.9, color='r', linestyle='--', label='Below model learns identity (IFFT)')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Acceleration factor', fontsize=12)\n",
    "plt.ylabel('Undersampling Error to Noise', fontsize=12)\n",
    "plt.title('Undersampling Error to Noise Error Ratio vs AF', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I plot MSE in image domain vs AF\n",
    "\n",
    "AF = [3,5,10,20,40]\n",
    "MSE_Model = [5767337, 7808766, 9472584, 10431753, 11269272]\n",
    "MSE_IFFT = [5742150, 7819783, 9631808, 10977836, 12765058]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(AF, MSE_Model, marker='o', linestyle='-', label='MSE_Model')\n",
    "\n",
    "plt.plot(AF, MSE_IFFT, marker='o', linestyle='-', label='MSE_IFFT')\n",
    "\n",
    "#plt.axvline(y=0.9, color='r', linestyle='--', label='Below model learns identity (IFFT)')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Acceleration factor', fontsize=12)\n",
    "plt.ylabel('MSE', fontsize=12)\n",
    "plt.title('MSE vs AF', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
