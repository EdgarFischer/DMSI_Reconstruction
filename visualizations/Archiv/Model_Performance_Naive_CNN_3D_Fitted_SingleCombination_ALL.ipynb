{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "In the Data folder file I showed that t>20 basically corresponds to noise. Here I want to check if the network performance improves if I throw out this noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('../scripts')\n",
    "sys.path.append('../models')\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= '0' #, this way I would choose GPU 3 to do the work\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import zoom # for compressing images / only for testing purposes to speed up NN training\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from data_preparation import *\n",
    "from data_undersampling import *\n",
    "from output_statistics import *\n",
    "\n",
    "from interlacer_layer_modified import *\n",
    "from Residual_Interlacer_modified import *\n",
    "from skimage.metrics import structural_similarity as ssim \n",
    "\n",
    "trancuate_t = 96 # set this parameter to control at which time step you stop using the signal\n",
    "# Set how many subsequent time steps you want to give to the network at once. Values allowed: 1, 2, 4, 8 (because it has to divide 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "num_convs = 10\n",
    "grouped_time_steps = 1\n",
    "r = 0\n",
    "\n",
    "\n",
    "#### Model import correct model\n",
    "from Naive_CNN_3D import * #from Naive_CNN_3D_Residual_No_Batch_Norm import *\n",
    "\n",
    "AF = 3 #                # defined so far for noisy:3, 5, 10, 20, 40\n",
    "\n",
    "#saved_model_path = \"../saved_models/Naive_CNN_3D_AF_3_Non_Residual/Layer/model.pth\"  # Replace with your file path\n",
    "#saved_model_path = \"../saved_models/Naive_CNN_3D_AF_3_possoin_r0/5Layer/model.pth\"\n",
    "#saved_model_path = \"../saved_models/Naive_CNN_3D_AF_3_Alternating/5Layer/model.pth\"\n",
    "#saved_model_path = \"../saved_models/Naive_CNN_3D_Non_Residual_AF_5_possoin_r0/5Layer/model.pth\"\n",
    "saved_model_path = f'../saved_models/Fitted_Naive_CNN_3D_AF_{AF}_possoin_r{r}_CombinedTimsteps_ALL/{num_convs}Layer/model.pth'\n",
    "\n",
    "#### Load data ####\n",
    "Ground_Truth = np.load('../data/Combined_Spectral_And_Full.npy')\n",
    "\n",
    "Undersampled_Data = np.load(f'../data/Undersampled_Data/combined_undersampled_possoin_3D_fixed_r{r}_AF_{AF}_CombinedTimsteps_ALL.npy')\n",
    "\n",
    "#Undersampled_Data = np.load('../data/Undersampled_Data/combined_undersampled_possoin_3D_fixed_r0_AF_5.npy')\n",
    "#Undersampled_Data = np.load('../data/Undersampled_Data/combined_undersampled_Alternating_AF_3.npy')\n",
    "#Undersampled_Data = np.load('../data/Undersampled_Data/combined_undersampled_possoin_3D_fixed_r0_AF_3.npy') ## Data set with accerleration factor 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train_Test_Split ####\n",
    "ground_truth_train, ground_truth_test = Ground_Truth[:,:,:,:,:,:6], Ground_Truth[:,:,:,:,:,6]  # Method: Leave last MRSI measurement as test set\n",
    "\n",
    "#### Assign undersampled network input ####\n",
    "NN_input_train, NN_input_test = Undersampled_Data[:,:,:,:,:,:6], Undersampled_Data[:,:,:,:,:,6]\n",
    "\n",
    "#### Fourier transform ####\n",
    "training_undersampled, test_undersampled = fourier_transform(NN_input_train), fourier_transform(NN_input_test)\n",
    "\n",
    "#### Collapse ununsed dimensions ####\n",
    "ground_truth_train, ground_truth_test = ground_truth_train.reshape(22, 22, 21, -1), ground_truth_test.reshape(22, 22, 21, -1)\n",
    "NN_input_train, NN_input_test = NN_input_train.reshape(22, 22, 21, -1), NN_input_test.reshape(22, 22, 21, -1)\n",
    "training_undersampled, test_undersampled = training_undersampled.reshape(22, 22, 21, -1), test_undersampled.reshape(22, 22, 21, -1)\n",
    "\n",
    "#### Normalize data #####\n",
    "normalized_input_train, normalized_ground_truth_train, norm_values_train = normalize_data_per_image_new(NN_input_train, ground_truth_train)\n",
    "normalized_input_test, normalized_ground_truth_test, norm_values_test = normalize_data_per_image_new(NN_input_test, ground_truth_test)\n",
    "_, normalized_train_FT, _ = normalize_data_per_image_new(NN_input_train, training_undersampled)\n",
    "_, normalized_test_FT, _ = normalize_data_per_image_new(NN_input_test, test_undersampled)\n",
    "\n",
    "#### reshape for pytorch ####\n",
    "train_data, train_labels  = reshape_for_pytorch(normalized_input_train, grouped_time_steps), reshape_for_pytorch(normalized_ground_truth_train, grouped_time_steps)\n",
    "test_data, test_labels = reshape_for_pytorch(normalized_input_test, grouped_time_steps), reshape_for_pytorch(normalized_ground_truth_test, grouped_time_steps)\n",
    "\n",
    "# Prepare k-space data (reshape undersampled k-space as well)\n",
    "train_k_space = reshape_for_pytorch(normalized_train_FT, grouped_time_steps)\n",
    "test_k_space = reshape_for_pytorch(normalized_test_FT, grouped_time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Set parameters ####\n",
    "\n",
    "# Create TensorDataset instances\n",
    "train_dataset = TensorDataset(train_data, train_labels)\n",
    "test_dataset = TensorDataset(test_data, test_labels)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "  # Number of convolutional layers\n",
    "model = Naive_CNN_3D(grouped_time_steps=grouped_time_steps, num_convs=num_convs, ).to(device)\n",
    "\n",
    "#saved_model_path = \"../saved_models/Naive_CNN_3D_AF_3_Non_Residual/5Layer/model.pth\"  # Replace with your file path\n",
    "\n",
    "# 2. Load the model's state_dict (weights) from the saved file\n",
    "\n",
    "checkpoint = torch.load(saved_model_path, map_location=device)\n",
    "# Extract the model state_dict\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_Outputs_Test_Set, ground_truth = Process_Model_Output(test_loader, model, device, trancuate_t, 8, grouped_time_steps, norm_values_test)\n",
    "\n",
    "Noise = ground_truth[:, :, :, 95, :]   # e.g. shape: (X, Y, Z, coil_dim)\n",
    "\n",
    "# Compute 2-norm per coil\n",
    "two_norm_per_big_T = np.sqrt(np.sum(np.abs(Noise)**2, axis=(0, 1, 2)))\n",
    "# shape of two_norm_per_coil is now (coil_dim,)\n",
    "\n",
    "# Take the mean across coils\n",
    "two_norm_noise_average = np.mean(two_norm_per_big_T)\n",
    "\n",
    "\n",
    "model_input = Undersampled_Data[:,:,:,:,:,6]\n",
    "\n",
    "Undersampling_Error = ground_truth[:, :, :, 0, :] - model_input[:, :, :, 0, :]  # e.g. shape: (X, Y, Z, coil_dim)\n",
    "\n",
    "# Compute 2-norm per coil\n",
    "two_norm_per_big_T = np.sqrt(np.sum(np.abs(Undersampling_Error)**2, axis=(0, 1, 2)))\n",
    "# shape of two_norm_per_coil is now (coil_dim,)\n",
    "\n",
    "# Take the mean across coils\n",
    "two_norm_US_average = np.mean(two_norm_per_big_T)\n",
    "\n",
    "Quotient = two_norm_US_average / two_norm_noise_average\n",
    "\n",
    "print(\"Undersampling error / noise error:\", Quotient)\n",
    "\n",
    "norm_values_test = norm_values_test.reshape(96,8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plot_general_statistics(Model_Outputs_Test_Set, model_input, ground_truth, trancuate_t, norm_values_test)\n",
    "plot_general_statistics_PSNR(Model_Outputs_Test_Set, model_input, ground_truth, trancuate_t, norm_values_test)\n",
    "plot_general_statistics_SSIM(Model_Outputs_Test_Set, model_input, ground_truth, trancuate_t, norm_values_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 1\n",
    "T = 7\n",
    "domain = \"time\"\n",
    "\n",
    "model_input = Undersampled_Data[:,:,:,:,:,6]\n",
    "\n",
    "comparison_Plot_3D_vs_Ifft(Model_Outputs_Test_Set, ground_truth, model_input, t, T, domain=domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Note that the Ratio is computed in the statistics cell\n",
    "\n",
    "AF = [3,5,10,20,40]\n",
    "Ratio = [0.73, 0.9, 1.04, 1.154, 1.73]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(AF, Ratio, marker='o', linestyle='-', label='Undersampling Error to Noise Error Ratio vs AF')\n",
    "\n",
    "plt.axhline(y=0.9, color='r', linestyle='--', label='Below model learns identity (IFFT)')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Acceleration factor', fontsize=12)\n",
    "plt.ylabel('Undersampling Error to Noise', fontsize=12)\n",
    "plt.title('Undersampling Error to Noise Error Ratio vs AF', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I plot MSE in image domain vs AF\n",
    "\n",
    "AF = [3,5,10,20,40]\n",
    "MSE_Model = [5767337, 7808766, 9472584, 10431753, 11269272]\n",
    "MSE_IFFT = [5742150, 7819783, 9631808, 10977836, 12765058]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(AF, MSE_Model, marker='o', linestyle='-', label='MSE_Model')\n",
    "\n",
    "plt.plot(AF, MSE_IFFT, marker='o', linestyle='-', label='MSE_IFFT')\n",
    "\n",
    "#plt.axvline(y=0.9, color='r', linestyle='--', label='Below model learns identity (IFFT)')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Acceleration factor', fontsize=12)\n",
    "plt.ylabel('MSE', fontsize=12)\n",
    "plt.title('MSE vs AF', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
